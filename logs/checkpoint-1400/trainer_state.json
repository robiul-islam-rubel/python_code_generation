{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6215316315205327,
  "eval_steps": 500,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004439511653718091,
      "grad_norm": 4.054643630981445,
      "learning_rate": 0.0004992599171107164,
      "loss": 2.352,
      "step": 10
    },
    {
      "epoch": 0.008879023307436182,
      "grad_norm": 2.477839469909668,
      "learning_rate": 0.0004985198342214328,
      "loss": 1.9176,
      "step": 20
    },
    {
      "epoch": 0.013318534961154272,
      "grad_norm": 2.748054027557373,
      "learning_rate": 0.0004977797513321492,
      "loss": 2.0735,
      "step": 30
    },
    {
      "epoch": 0.017758046614872364,
      "grad_norm": 2.6057891845703125,
      "learning_rate": 0.0004970396684428656,
      "loss": 1.7736,
      "step": 40
    },
    {
      "epoch": 0.022197558268590455,
      "grad_norm": 1.843123197555542,
      "learning_rate": 0.000496299585553582,
      "loss": 1.822,
      "step": 50
    },
    {
      "epoch": 0.026637069922308545,
      "grad_norm": 1.7726880311965942,
      "learning_rate": 0.0004956335109532268,
      "loss": 1.7889,
      "step": 60
    },
    {
      "epoch": 0.03107658157602664,
      "grad_norm": 2.047724485397339,
      "learning_rate": 0.0004948934280639432,
      "loss": 1.6535,
      "step": 70
    },
    {
      "epoch": 0.03551609322974473,
      "grad_norm": 1.8672618865966797,
      "learning_rate": 0.0004941533451746596,
      "loss": 1.6607,
      "step": 80
    },
    {
      "epoch": 0.03995560488346282,
      "grad_norm": 2.528557538986206,
      "learning_rate": 0.000493413262285376,
      "loss": 1.7816,
      "step": 90
    },
    {
      "epoch": 0.04439511653718091,
      "grad_norm": 2.168644905090332,
      "learning_rate": 0.0004926731793960924,
      "loss": 1.5275,
      "step": 100
    },
    {
      "epoch": 0.048834628190899,
      "grad_norm": 2.151695728302002,
      "learning_rate": 0.0004919330965068088,
      "loss": 1.7346,
      "step": 110
    },
    {
      "epoch": 0.05327413984461709,
      "grad_norm": 2.0462753772735596,
      "learning_rate": 0.0004911930136175252,
      "loss": 1.5574,
      "step": 120
    },
    {
      "epoch": 0.05771365149833518,
      "grad_norm": 1.5268481969833374,
      "learning_rate": 0.0004904529307282416,
      "loss": 1.6383,
      "step": 130
    },
    {
      "epoch": 0.06215316315205328,
      "grad_norm": 2.150617837905884,
      "learning_rate": 0.000489712847838958,
      "loss": 1.6846,
      "step": 140
    },
    {
      "epoch": 0.06659267480577137,
      "grad_norm": 2.586848020553589,
      "learning_rate": 0.0004889727649496743,
      "loss": 1.5786,
      "step": 150
    },
    {
      "epoch": 0.07103218645948946,
      "grad_norm": 1.9333423376083374,
      "learning_rate": 0.00048823268206039076,
      "loss": 1.7571,
      "step": 160
    },
    {
      "epoch": 0.07547169811320754,
      "grad_norm": 3.1580400466918945,
      "learning_rate": 0.00048749259917110717,
      "loss": 1.6413,
      "step": 170
    },
    {
      "epoch": 0.07991120976692564,
      "grad_norm": 2.201777458190918,
      "learning_rate": 0.00048675251628182357,
      "loss": 1.6637,
      "step": 180
    },
    {
      "epoch": 0.08435072142064373,
      "grad_norm": 1.5520122051239014,
      "learning_rate": 0.00048601243339254,
      "loss": 1.5949,
      "step": 190
    },
    {
      "epoch": 0.08879023307436182,
      "grad_norm": 3.2420663833618164,
      "learning_rate": 0.0004852723505032564,
      "loss": 1.5658,
      "step": 200
    },
    {
      "epoch": 0.0932297447280799,
      "grad_norm": 2.1900508403778076,
      "learning_rate": 0.0004845322676139728,
      "loss": 1.5863,
      "step": 210
    },
    {
      "epoch": 0.097669256381798,
      "grad_norm": 2.21549391746521,
      "learning_rate": 0.0004837921847246892,
      "loss": 1.4758,
      "step": 220
    },
    {
      "epoch": 0.10210876803551609,
      "grad_norm": 2.064615488052368,
      "learning_rate": 0.0004830521018354056,
      "loss": 1.55,
      "step": 230
    },
    {
      "epoch": 0.10654827968923418,
      "grad_norm": 2.525146961212158,
      "learning_rate": 0.000482312018946122,
      "loss": 1.5399,
      "step": 240
    },
    {
      "epoch": 0.11098779134295228,
      "grad_norm": 2.0821399688720703,
      "learning_rate": 0.00048157193605683835,
      "loss": 1.4429,
      "step": 250
    },
    {
      "epoch": 0.11542730299667037,
      "grad_norm": 1.58427894115448,
      "learning_rate": 0.0004808318531675548,
      "loss": 1.4108,
      "step": 260
    },
    {
      "epoch": 0.11986681465038845,
      "grad_norm": 2.192683696746826,
      "learning_rate": 0.00048009177027827116,
      "loss": 1.4006,
      "step": 270
    },
    {
      "epoch": 0.12430632630410655,
      "grad_norm": 1.5377377271652222,
      "learning_rate": 0.0004793516873889876,
      "loss": 1.3984,
      "step": 280
    },
    {
      "epoch": 0.12874583795782463,
      "grad_norm": 2.260063409805298,
      "learning_rate": 0.00047861160449970397,
      "loss": 1.4997,
      "step": 290
    },
    {
      "epoch": 0.13318534961154274,
      "grad_norm": 3.4104886054992676,
      "learning_rate": 0.0004778715216104204,
      "loss": 1.4686,
      "step": 300
    },
    {
      "epoch": 0.13762486126526083,
      "grad_norm": 2.8780131340026855,
      "learning_rate": 0.0004771314387211368,
      "loss": 1.6059,
      "step": 310
    },
    {
      "epoch": 0.14206437291897892,
      "grad_norm": 2.854306221008301,
      "learning_rate": 0.0004763913558318532,
      "loss": 1.6074,
      "step": 320
    },
    {
      "epoch": 0.146503884572697,
      "grad_norm": 1.7294703722000122,
      "learning_rate": 0.0004756512729425696,
      "loss": 1.5092,
      "step": 330
    },
    {
      "epoch": 0.1509433962264151,
      "grad_norm": 2.494455099105835,
      "learning_rate": 0.000474911190053286,
      "loss": 1.4524,
      "step": 340
    },
    {
      "epoch": 0.15538290788013318,
      "grad_norm": 2.055124521255493,
      "learning_rate": 0.00047417110716400235,
      "loss": 1.4831,
      "step": 350
    },
    {
      "epoch": 0.1598224195338513,
      "grad_norm": 2.6806280612945557,
      "learning_rate": 0.0004734310242747188,
      "loss": 1.5829,
      "step": 360
    },
    {
      "epoch": 0.16426193118756938,
      "grad_norm": 2.334710121154785,
      "learning_rate": 0.00047269094138543516,
      "loss": 1.5037,
      "step": 370
    },
    {
      "epoch": 0.16870144284128746,
      "grad_norm": 3.8841795921325684,
      "learning_rate": 0.0004719508584961516,
      "loss": 1.4424,
      "step": 380
    },
    {
      "epoch": 0.17314095449500555,
      "grad_norm": 3.0745744705200195,
      "learning_rate": 0.00047121077560686797,
      "loss": 1.4201,
      "step": 390
    },
    {
      "epoch": 0.17758046614872364,
      "grad_norm": 2.2438924312591553,
      "learning_rate": 0.00047047069271758437,
      "loss": 1.4589,
      "step": 400
    },
    {
      "epoch": 0.18201997780244172,
      "grad_norm": 2.606391429901123,
      "learning_rate": 0.0004697306098283008,
      "loss": 1.5147,
      "step": 410
    },
    {
      "epoch": 0.1864594894561598,
      "grad_norm": 1.9846000671386719,
      "learning_rate": 0.0004689905269390172,
      "loss": 1.6754,
      "step": 420
    },
    {
      "epoch": 0.19089900110987792,
      "grad_norm": 2.0650007724761963,
      "learning_rate": 0.0004682504440497336,
      "loss": 1.4663,
      "step": 430
    },
    {
      "epoch": 0.195338512763596,
      "grad_norm": 1.969778060913086,
      "learning_rate": 0.00046751036116045,
      "loss": 1.4181,
      "step": 440
    },
    {
      "epoch": 0.1997780244173141,
      "grad_norm": 2.866069793701172,
      "learning_rate": 0.00046677027827116634,
      "loss": 1.3834,
      "step": 450
    },
    {
      "epoch": 0.20421753607103219,
      "grad_norm": 2.133826494216919,
      "learning_rate": 0.0004660301953818828,
      "loss": 1.4518,
      "step": 460
    },
    {
      "epoch": 0.20865704772475027,
      "grad_norm": 2.4633429050445557,
      "learning_rate": 0.00046529011249259915,
      "loss": 1.4814,
      "step": 470
    },
    {
      "epoch": 0.21309655937846836,
      "grad_norm": 1.6882880926132202,
      "learning_rate": 0.0004645500296033156,
      "loss": 1.4354,
      "step": 480
    },
    {
      "epoch": 0.21753607103218647,
      "grad_norm": 2.161064624786377,
      "learning_rate": 0.00046380994671403196,
      "loss": 1.4254,
      "step": 490
    },
    {
      "epoch": 0.22197558268590456,
      "grad_norm": 3.765519142150879,
      "learning_rate": 0.00046306986382474837,
      "loss": 1.4999,
      "step": 500
    },
    {
      "epoch": 0.22641509433962265,
      "grad_norm": 2.3685739040374756,
      "learning_rate": 0.00046232978093546477,
      "loss": 1.4368,
      "step": 510
    },
    {
      "epoch": 0.23085460599334073,
      "grad_norm": 1.8080672025680542,
      "learning_rate": 0.0004615896980461812,
      "loss": 1.4922,
      "step": 520
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 3.117081880569458,
      "learning_rate": 0.0004608496151568976,
      "loss": 1.4003,
      "step": 530
    },
    {
      "epoch": 0.2397336293007769,
      "grad_norm": 1.7682117223739624,
      "learning_rate": 0.000460109532267614,
      "loss": 1.489,
      "step": 540
    },
    {
      "epoch": 0.244173140954495,
      "grad_norm": 2.2536675930023193,
      "learning_rate": 0.00045936944937833034,
      "loss": 1.5295,
      "step": 550
    },
    {
      "epoch": 0.2486126526082131,
      "grad_norm": 2.2390410900115967,
      "learning_rate": 0.0004586293664890468,
      "loss": 1.3979,
      "step": 560
    },
    {
      "epoch": 0.25305216426193117,
      "grad_norm": 2.209352731704712,
      "learning_rate": 0.0004578892835997632,
      "loss": 1.4194,
      "step": 570
    },
    {
      "epoch": 0.25749167591564925,
      "grad_norm": 2.129152536392212,
      "learning_rate": 0.0004571492007104796,
      "loss": 1.394,
      "step": 580
    },
    {
      "epoch": 0.2619311875693674,
      "grad_norm": 2.003588914871216,
      "learning_rate": 0.000456409117821196,
      "loss": 1.2182,
      "step": 590
    },
    {
      "epoch": 0.2663706992230855,
      "grad_norm": 1.967622995376587,
      "learning_rate": 0.00045566903493191236,
      "loss": 1.5414,
      "step": 600
    },
    {
      "epoch": 0.27081021087680357,
      "grad_norm": 2.4503138065338135,
      "learning_rate": 0.0004549289520426288,
      "loss": 1.3881,
      "step": 610
    },
    {
      "epoch": 0.27524972253052166,
      "grad_norm": 2.1452744007110596,
      "learning_rate": 0.00045418886915334517,
      "loss": 1.3729,
      "step": 620
    },
    {
      "epoch": 0.27968923418423974,
      "grad_norm": 2.611724615097046,
      "learning_rate": 0.00045344878626406163,
      "loss": 1.4539,
      "step": 630
    },
    {
      "epoch": 0.28412874583795783,
      "grad_norm": 2.1509506702423096,
      "learning_rate": 0.000452708703374778,
      "loss": 1.4869,
      "step": 640
    },
    {
      "epoch": 0.2885682574916759,
      "grad_norm": 1.7710063457489014,
      "learning_rate": 0.0004519686204854944,
      "loss": 1.4636,
      "step": 650
    },
    {
      "epoch": 0.293007769145394,
      "grad_norm": 2.103294610977173,
      "learning_rate": 0.0004512285375962108,
      "loss": 1.3811,
      "step": 660
    },
    {
      "epoch": 0.2974472807991121,
      "grad_norm": 2.388345956802368,
      "learning_rate": 0.0004504884547069272,
      "loss": 1.3846,
      "step": 670
    },
    {
      "epoch": 0.3018867924528302,
      "grad_norm": 2.7555673122406006,
      "learning_rate": 0.0004497483718176436,
      "loss": 1.4782,
      "step": 680
    },
    {
      "epoch": 0.30632630410654826,
      "grad_norm": 2.0017216205596924,
      "learning_rate": 0.00044900828892836,
      "loss": 1.3683,
      "step": 690
    },
    {
      "epoch": 0.31076581576026635,
      "grad_norm": 2.90942120552063,
      "learning_rate": 0.00044826820603907636,
      "loss": 1.3179,
      "step": 700
    },
    {
      "epoch": 0.31520532741398444,
      "grad_norm": 2.5046520233154297,
      "learning_rate": 0.0004475281231497928,
      "loss": 1.4616,
      "step": 710
    },
    {
      "epoch": 0.3196448390677026,
      "grad_norm": 1.8346855640411377,
      "learning_rate": 0.00044678804026050917,
      "loss": 1.2704,
      "step": 720
    },
    {
      "epoch": 0.32408435072142067,
      "grad_norm": 1.8805220127105713,
      "learning_rate": 0.0004460479573712256,
      "loss": 1.3124,
      "step": 730
    },
    {
      "epoch": 0.32852386237513875,
      "grad_norm": 2.064824342727661,
      "learning_rate": 0.000445307874481942,
      "loss": 1.4841,
      "step": 740
    },
    {
      "epoch": 0.33296337402885684,
      "grad_norm": 2.6950631141662598,
      "learning_rate": 0.0004445677915926584,
      "loss": 1.4189,
      "step": 750
    },
    {
      "epoch": 0.3374028856825749,
      "grad_norm": 2.8344624042510986,
      "learning_rate": 0.0004438277087033748,
      "loss": 1.6122,
      "step": 760
    },
    {
      "epoch": 0.341842397336293,
      "grad_norm": 2.25856351852417,
      "learning_rate": 0.0004430876258140912,
      "loss": 1.3434,
      "step": 770
    },
    {
      "epoch": 0.3462819089900111,
      "grad_norm": 3.7481534481048584,
      "learning_rate": 0.0004423475429248076,
      "loss": 1.4331,
      "step": 780
    },
    {
      "epoch": 0.3507214206437292,
      "grad_norm": 2.2983579635620117,
      "learning_rate": 0.000441607460035524,
      "loss": 1.389,
      "step": 790
    },
    {
      "epoch": 0.3551609322974473,
      "grad_norm": 1.9178669452667236,
      "learning_rate": 0.00044086737714624035,
      "loss": 1.3596,
      "step": 800
    },
    {
      "epoch": 0.35960044395116536,
      "grad_norm": 2.607564926147461,
      "learning_rate": 0.0004401272942569568,
      "loss": 1.3677,
      "step": 810
    },
    {
      "epoch": 0.36403995560488345,
      "grad_norm": 1.7786167860031128,
      "learning_rate": 0.00043938721136767316,
      "loss": 1.3581,
      "step": 820
    },
    {
      "epoch": 0.36847946725860153,
      "grad_norm": 1.9138953685760498,
      "learning_rate": 0.0004386471284783896,
      "loss": 1.3118,
      "step": 830
    },
    {
      "epoch": 0.3729189789123196,
      "grad_norm": 2.3295493125915527,
      "learning_rate": 0.00043790704558910597,
      "loss": 1.425,
      "step": 840
    },
    {
      "epoch": 0.37735849056603776,
      "grad_norm": 2.2294840812683105,
      "learning_rate": 0.0004371669626998224,
      "loss": 1.4387,
      "step": 850
    },
    {
      "epoch": 0.38179800221975585,
      "grad_norm": 2.571744918823242,
      "learning_rate": 0.0004364268798105388,
      "loss": 1.1943,
      "step": 860
    },
    {
      "epoch": 0.38623751387347394,
      "grad_norm": 3.9955742359161377,
      "learning_rate": 0.0004356867969212552,
      "loss": 1.5068,
      "step": 870
    },
    {
      "epoch": 0.390677025527192,
      "grad_norm": 1.9013206958770752,
      "learning_rate": 0.0004349467140319716,
      "loss": 1.3918,
      "step": 880
    },
    {
      "epoch": 0.3951165371809101,
      "grad_norm": 2.1233904361724854,
      "learning_rate": 0.000434206631142688,
      "loss": 1.3743,
      "step": 890
    },
    {
      "epoch": 0.3995560488346282,
      "grad_norm": 2.040383815765381,
      "learning_rate": 0.00043346654825340435,
      "loss": 1.3621,
      "step": 900
    },
    {
      "epoch": 0.4039955604883463,
      "grad_norm": 3.0131123065948486,
      "learning_rate": 0.0004327264653641208,
      "loss": 1.4435,
      "step": 910
    },
    {
      "epoch": 0.40843507214206437,
      "grad_norm": 3.830791711807251,
      "learning_rate": 0.00043198638247483716,
      "loss": 1.3214,
      "step": 920
    },
    {
      "epoch": 0.41287458379578246,
      "grad_norm": 2.083017349243164,
      "learning_rate": 0.0004312462995855536,
      "loss": 1.4802,
      "step": 930
    },
    {
      "epoch": 0.41731409544950054,
      "grad_norm": 2.2863805294036865,
      "learning_rate": 0.00043050621669627,
      "loss": 1.35,
      "step": 940
    },
    {
      "epoch": 0.42175360710321863,
      "grad_norm": 3.8747406005859375,
      "learning_rate": 0.00042976613380698637,
      "loss": 1.2948,
      "step": 950
    },
    {
      "epoch": 0.4261931187569367,
      "grad_norm": 2.510215997695923,
      "learning_rate": 0.00042902605091770283,
      "loss": 1.3056,
      "step": 960
    },
    {
      "epoch": 0.4306326304106548,
      "grad_norm": 2.4046311378479004,
      "learning_rate": 0.0004282859680284192,
      "loss": 1.3578,
      "step": 970
    },
    {
      "epoch": 0.43507214206437295,
      "grad_norm": 1.803960919380188,
      "learning_rate": 0.00042754588513913564,
      "loss": 1.4015,
      "step": 980
    },
    {
      "epoch": 0.43951165371809103,
      "grad_norm": 1.5232865810394287,
      "learning_rate": 0.000426805802249852,
      "loss": 1.4134,
      "step": 990
    },
    {
      "epoch": 0.4439511653718091,
      "grad_norm": 1.850748062133789,
      "learning_rate": 0.0004260657193605684,
      "loss": 1.2966,
      "step": 1000
    },
    {
      "epoch": 0.4483906770255272,
      "grad_norm": 3.298250198364258,
      "learning_rate": 0.0004253256364712848,
      "loss": 1.301,
      "step": 1010
    },
    {
      "epoch": 0.4528301886792453,
      "grad_norm": 2.6895077228546143,
      "learning_rate": 0.0004246595618709296,
      "loss": 1.2867,
      "step": 1020
    },
    {
      "epoch": 0.4572697003329634,
      "grad_norm": 2.4650585651397705,
      "learning_rate": 0.00042391947898164594,
      "loss": 1.3447,
      "step": 1030
    },
    {
      "epoch": 0.46170921198668147,
      "grad_norm": 2.47660756111145,
      "learning_rate": 0.00042317939609236234,
      "loss": 1.3688,
      "step": 1040
    },
    {
      "epoch": 0.46614872364039955,
      "grad_norm": 2.0048694610595703,
      "learning_rate": 0.00042243931320307875,
      "loss": 1.3055,
      "step": 1050
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 2.7688956260681152,
      "learning_rate": 0.00042169923031379515,
      "loss": 1.3676,
      "step": 1060
    },
    {
      "epoch": 0.4750277469478357,
      "grad_norm": 2.5110268592834473,
      "learning_rate": 0.00042095914742451156,
      "loss": 1.3522,
      "step": 1070
    },
    {
      "epoch": 0.4794672586015538,
      "grad_norm": 2.1339023113250732,
      "learning_rate": 0.00042021906453522796,
      "loss": 1.239,
      "step": 1080
    },
    {
      "epoch": 0.4839067702552719,
      "grad_norm": 2.849062204360962,
      "learning_rate": 0.0004194789816459443,
      "loss": 1.3378,
      "step": 1090
    },
    {
      "epoch": 0.48834628190899,
      "grad_norm": 2.0617716312408447,
      "learning_rate": 0.00041873889875666077,
      "loss": 1.2474,
      "step": 1100
    },
    {
      "epoch": 0.49278579356270813,
      "grad_norm": 2.1087727546691895,
      "learning_rate": 0.0004179988158673771,
      "loss": 1.2378,
      "step": 1110
    },
    {
      "epoch": 0.4972253052164262,
      "grad_norm": 2.3770649433135986,
      "learning_rate": 0.0004172587329780936,
      "loss": 1.2649,
      "step": 1120
    },
    {
      "epoch": 0.5016648168701443,
      "grad_norm": 2.892982244491577,
      "learning_rate": 0.00041651865008881,
      "loss": 1.3096,
      "step": 1130
    },
    {
      "epoch": 0.5061043285238623,
      "grad_norm": 3.1324703693389893,
      "learning_rate": 0.00041577856719952634,
      "loss": 1.3468,
      "step": 1140
    },
    {
      "epoch": 0.5105438401775805,
      "grad_norm": 2.302788019180298,
      "learning_rate": 0.0004150384843102428,
      "loss": 1.5017,
      "step": 1150
    },
    {
      "epoch": 0.5149833518312985,
      "grad_norm": 2.7934770584106445,
      "learning_rate": 0.00041429840142095915,
      "loss": 1.1984,
      "step": 1160
    },
    {
      "epoch": 0.5194228634850167,
      "grad_norm": 2.149888038635254,
      "learning_rate": 0.0004135583185316756,
      "loss": 1.4468,
      "step": 1170
    },
    {
      "epoch": 0.5238623751387348,
      "grad_norm": 2.188237428665161,
      "learning_rate": 0.00041281823564239196,
      "loss": 1.2426,
      "step": 1180
    },
    {
      "epoch": 0.5283018867924528,
      "grad_norm": 2.5798327922821045,
      "learning_rate": 0.00041207815275310836,
      "loss": 1.3429,
      "step": 1190
    },
    {
      "epoch": 0.532741398446171,
      "grad_norm": 2.389024019241333,
      "learning_rate": 0.00041133806986382477,
      "loss": 1.349,
      "step": 1200
    },
    {
      "epoch": 0.537180910099889,
      "grad_norm": 1.64403235912323,
      "learning_rate": 0.00041059798697454117,
      "loss": 1.3302,
      "step": 1210
    },
    {
      "epoch": 0.5416204217536071,
      "grad_norm": 1.824286699295044,
      "learning_rate": 0.0004098579040852576,
      "loss": 1.3638,
      "step": 1220
    },
    {
      "epoch": 0.5460599334073252,
      "grad_norm": 1.6353033781051636,
      "learning_rate": 0.000409117821195974,
      "loss": 1.47,
      "step": 1230
    },
    {
      "epoch": 0.5504994450610433,
      "grad_norm": 1.9310777187347412,
      "learning_rate": 0.00040837773830669033,
      "loss": 1.3305,
      "step": 1240
    },
    {
      "epoch": 0.5549389567147613,
      "grad_norm": 2.2481529712677,
      "learning_rate": 0.0004076376554174068,
      "loss": 1.4085,
      "step": 1250
    },
    {
      "epoch": 0.5593784683684795,
      "grad_norm": 2.4630343914031982,
      "learning_rate": 0.00040689757252812314,
      "loss": 1.2791,
      "step": 1260
    },
    {
      "epoch": 0.5638179800221975,
      "grad_norm": 1.8748359680175781,
      "learning_rate": 0.0004061574896388396,
      "loss": 1.1222,
      "step": 1270
    },
    {
      "epoch": 0.5682574916759157,
      "grad_norm": 2.4667835235595703,
      "learning_rate": 0.00040541740674955595,
      "loss": 1.2666,
      "step": 1280
    },
    {
      "epoch": 0.5726970033296337,
      "grad_norm": 2.185810089111328,
      "learning_rate": 0.00040467732386027236,
      "loss": 1.2362,
      "step": 1290
    },
    {
      "epoch": 0.5771365149833518,
      "grad_norm": 2.8877182006835938,
      "learning_rate": 0.00040393724097098876,
      "loss": 1.4745,
      "step": 1300
    },
    {
      "epoch": 0.58157602663707,
      "grad_norm": 2.3007447719573975,
      "learning_rate": 0.00040319715808170517,
      "loss": 1.4565,
      "step": 1310
    },
    {
      "epoch": 0.586015538290788,
      "grad_norm": 2.2806577682495117,
      "learning_rate": 0.00040245707519242157,
      "loss": 1.2963,
      "step": 1320
    },
    {
      "epoch": 0.5904550499445061,
      "grad_norm": 2.3302412033081055,
      "learning_rate": 0.000401716992303138,
      "loss": 1.2644,
      "step": 1330
    },
    {
      "epoch": 0.5948945615982242,
      "grad_norm": 2.422548532485962,
      "learning_rate": 0.0004009769094138543,
      "loss": 1.3935,
      "step": 1340
    },
    {
      "epoch": 0.5993340732519423,
      "grad_norm": 2.364901542663574,
      "learning_rate": 0.0004002368265245708,
      "loss": 1.2859,
      "step": 1350
    },
    {
      "epoch": 0.6037735849056604,
      "grad_norm": 2.2721052169799805,
      "learning_rate": 0.00039949674363528714,
      "loss": 1.2598,
      "step": 1360
    },
    {
      "epoch": 0.6082130965593785,
      "grad_norm": 2.7273976802825928,
      "learning_rate": 0.0003987566607460036,
      "loss": 1.4341,
      "step": 1370
    },
    {
      "epoch": 0.6126526082130965,
      "grad_norm": 2.987922191619873,
      "learning_rate": 0.00039801657785671995,
      "loss": 1.357,
      "step": 1380
    },
    {
      "epoch": 0.6170921198668147,
      "grad_norm": 2.6135194301605225,
      "learning_rate": 0.00039727649496743635,
      "loss": 1.3516,
      "step": 1390
    },
    {
      "epoch": 0.6215316315205327,
      "grad_norm": 2.7479171752929688,
      "learning_rate": 0.00039653641207815276,
      "loss": 1.3379,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 6756,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2217683504332800.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
