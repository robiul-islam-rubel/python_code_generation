{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 25762,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019408431022436147,
      "grad_norm": 3.0156495571136475,
      "learning_rate": 1.9871904355251923e-05,
      "loss": 6.0953,
      "step": 500
    },
    {
      "epoch": 0.038816862044872294,
      "grad_norm": 2.5376834869384766,
      "learning_rate": 1.974251481510235e-05,
      "loss": 5.175,
      "step": 1000
    },
    {
      "epoch": 0.05822529306730844,
      "grad_norm": 3.942051887512207,
      "learning_rate": 1.9613125274952772e-05,
      "loss": 5.1,
      "step": 1500
    },
    {
      "epoch": 0.07763372408974459,
      "grad_norm": 4.331577777862549,
      "learning_rate": 1.94837357348032e-05,
      "loss": 5.0535,
      "step": 2000
    },
    {
      "epoch": 0.09704215511218073,
      "grad_norm": 3.4310264587402344,
      "learning_rate": 1.9354346194653627e-05,
      "loss": 5.051,
      "step": 2500
    },
    {
      "epoch": 0.11645058613461688,
      "grad_norm": 3.5291943550109863,
      "learning_rate": 1.9224956654504052e-05,
      "loss": 5.0154,
      "step": 3000
    },
    {
      "epoch": 0.13585901715705304,
      "grad_norm": 4.405115604400635,
      "learning_rate": 1.9095567114354476e-05,
      "loss": 4.9982,
      "step": 3500
    },
    {
      "epoch": 0.15526744817948918,
      "grad_norm": 5.135713577270508,
      "learning_rate": 1.8966177574204904e-05,
      "loss": 4.9702,
      "step": 4000
    },
    {
      "epoch": 0.17467587920192532,
      "grad_norm": 3.2893805503845215,
      "learning_rate": 1.883678803405533e-05,
      "loss": 4.9703,
      "step": 4500
    },
    {
      "epoch": 0.19408431022436146,
      "grad_norm": 6.493264675140381,
      "learning_rate": 1.8707398493905756e-05,
      "loss": 4.9742,
      "step": 5000
    },
    {
      "epoch": 0.2134927412467976,
      "grad_norm": 4.357235431671143,
      "learning_rate": 1.857800895375618e-05,
      "loss": 4.9568,
      "step": 5500
    },
    {
      "epoch": 0.23290117226923376,
      "grad_norm": 2.8122124671936035,
      "learning_rate": 1.8448619413606605e-05,
      "loss": 4.9517,
      "step": 6000
    },
    {
      "epoch": 0.2523096032916699,
      "grad_norm": 3.5628552436828613,
      "learning_rate": 1.8319229873457033e-05,
      "loss": 4.9229,
      "step": 6500
    },
    {
      "epoch": 0.27171803431410607,
      "grad_norm": 3.464205503463745,
      "learning_rate": 1.8189840333307457e-05,
      "loss": 4.9347,
      "step": 7000
    },
    {
      "epoch": 0.2911264653365422,
      "grad_norm": 3.894460916519165,
      "learning_rate": 1.806045079315788e-05,
      "loss": 4.9191,
      "step": 7500
    },
    {
      "epoch": 0.31053489635897835,
      "grad_norm": 3.4287831783294678,
      "learning_rate": 1.793106125300831e-05,
      "loss": 4.926,
      "step": 8000
    },
    {
      "epoch": 0.32994332738141446,
      "grad_norm": 4.080543518066406,
      "learning_rate": 1.7801671712858734e-05,
      "loss": 4.9238,
      "step": 8500
    },
    {
      "epoch": 0.34935175840385063,
      "grad_norm": 3.5280754566192627,
      "learning_rate": 1.767228217270916e-05,
      "loss": 4.9193,
      "step": 9000
    },
    {
      "epoch": 0.3687601894262868,
      "grad_norm": 4.128464221954346,
      "learning_rate": 1.7542892632559586e-05,
      "loss": 4.9027,
      "step": 9500
    },
    {
      "epoch": 0.3881686204487229,
      "grad_norm": 4.004984378814697,
      "learning_rate": 1.741376187149031e-05,
      "loss": 4.8945,
      "step": 10000
    },
    {
      "epoch": 0.4075770514711591,
      "grad_norm": 3.562501907348633,
      "learning_rate": 1.7284372331340736e-05,
      "loss": 4.9077,
      "step": 10500
    },
    {
      "epoch": 0.4269854824935952,
      "grad_norm": 3.1492257118225098,
      "learning_rate": 1.715498279119116e-05,
      "loss": 4.8967,
      "step": 11000
    },
    {
      "epoch": 0.44639391351603136,
      "grad_norm": 4.780231952667236,
      "learning_rate": 1.7025593251041588e-05,
      "loss": 4.8736,
      "step": 11500
    },
    {
      "epoch": 0.4658023445384675,
      "grad_norm": 3.2589855194091797,
      "learning_rate": 1.6896203710892012e-05,
      "loss": 4.8896,
      "step": 12000
    },
    {
      "epoch": 0.48521077556090364,
      "grad_norm": 3.1079773902893066,
      "learning_rate": 1.6766814170742437e-05,
      "loss": 4.8893,
      "step": 12500
    },
    {
      "epoch": 0.5046192065833398,
      "grad_norm": 3.26347279548645,
      "learning_rate": 1.6637424630592865e-05,
      "loss": 4.8899,
      "step": 13000
    },
    {
      "epoch": 0.524027637605776,
      "grad_norm": 3.2418606281280518,
      "learning_rate": 1.6508035090443292e-05,
      "loss": 4.9097,
      "step": 13500
    },
    {
      "epoch": 0.5434360686282121,
      "grad_norm": 4.905200004577637,
      "learning_rate": 1.6378904329374014e-05,
      "loss": 4.8878,
      "step": 14000
    },
    {
      "epoch": 0.5628444996506482,
      "grad_norm": 3.583787202835083,
      "learning_rate": 1.6249514789224442e-05,
      "loss": 4.8834,
      "step": 14500
    },
    {
      "epoch": 0.5822529306730844,
      "grad_norm": 4.404994487762451,
      "learning_rate": 1.6120125249074866e-05,
      "loss": 4.8527,
      "step": 15000
    },
    {
      "epoch": 0.6016613616955205,
      "grad_norm": 3.8764243125915527,
      "learning_rate": 1.599073570892529e-05,
      "loss": 4.8945,
      "step": 15500
    },
    {
      "epoch": 0.6210697927179567,
      "grad_norm": 6.267667770385742,
      "learning_rate": 1.586134616877572e-05,
      "loss": 4.8602,
      "step": 16000
    },
    {
      "epoch": 0.6404782237403929,
      "grad_norm": 4.009965419769287,
      "learning_rate": 1.5731956628626143e-05,
      "loss": 4.863,
      "step": 16500
    },
    {
      "epoch": 0.6598866547628289,
      "grad_norm": 3.580256938934326,
      "learning_rate": 1.5602567088476567e-05,
      "loss": 4.8768,
      "step": 17000
    },
    {
      "epoch": 0.6792950857852651,
      "grad_norm": 5.5662760734558105,
      "learning_rate": 1.5473436327407293e-05,
      "loss": 4.8725,
      "step": 17500
    },
    {
      "epoch": 0.6987035168077013,
      "grad_norm": 3.416393280029297,
      "learning_rate": 1.534404678725772e-05,
      "loss": 4.8737,
      "step": 18000
    },
    {
      "epoch": 0.7181119478301374,
      "grad_norm": 3.1308705806732178,
      "learning_rate": 1.5214916026188444e-05,
      "loss": 4.8617,
      "step": 18500
    },
    {
      "epoch": 0.7375203788525736,
      "grad_norm": 3.2318172454833984,
      "learning_rate": 1.508552648603887e-05,
      "loss": 4.8644,
      "step": 19000
    },
    {
      "epoch": 0.7569288098750097,
      "grad_norm": 2.86999773979187,
      "learning_rate": 1.4956136945889294e-05,
      "loss": 4.8451,
      "step": 19500
    },
    {
      "epoch": 0.7763372408974458,
      "grad_norm": 4.827009677886963,
      "learning_rate": 1.482674740573972e-05,
      "loss": 4.8598,
      "step": 20000
    },
    {
      "epoch": 0.795745671919882,
      "grad_norm": 3.603459358215332,
      "learning_rate": 1.4697357865590147e-05,
      "loss": 4.8578,
      "step": 20500
    },
    {
      "epoch": 0.8151541029423182,
      "grad_norm": 5.074081897735596,
      "learning_rate": 1.4567968325440574e-05,
      "loss": 4.8673,
      "step": 21000
    },
    {
      "epoch": 0.8345625339647543,
      "grad_norm": 3.7811038494110107,
      "learning_rate": 1.4438578785290997e-05,
      "loss": 4.8615,
      "step": 21500
    },
    {
      "epoch": 0.8539709649871904,
      "grad_norm": 2.9897711277008057,
      "learning_rate": 1.4309189245141423e-05,
      "loss": 4.8524,
      "step": 22000
    },
    {
      "epoch": 0.8733793960096266,
      "grad_norm": 4.158779621124268,
      "learning_rate": 1.417979970499185e-05,
      "loss": 4.8449,
      "step": 22500
    },
    {
      "epoch": 0.8927878270320627,
      "grad_norm": 3.920840263366699,
      "learning_rate": 1.4050410164842277e-05,
      "loss": 4.8488,
      "step": 23000
    },
    {
      "epoch": 0.9121962580544989,
      "grad_norm": 3.6061723232269287,
      "learning_rate": 1.39210206246927e-05,
      "loss": 4.8442,
      "step": 23500
    },
    {
      "epoch": 0.931604689076935,
      "grad_norm": 7.652431488037109,
      "learning_rate": 1.3791631084543126e-05,
      "loss": 4.8478,
      "step": 24000
    },
    {
      "epoch": 0.9510131200993711,
      "grad_norm": 5.96688175201416,
      "learning_rate": 1.3662241544393554e-05,
      "loss": 4.8517,
      "step": 24500
    },
    {
      "epoch": 0.9704215511218073,
      "grad_norm": 3.919732093811035,
      "learning_rate": 1.3533110783324277e-05,
      "loss": 4.8453,
      "step": 25000
    },
    {
      "epoch": 0.9898299821442434,
      "grad_norm": 4.069413661956787,
      "learning_rate": 1.3403721243174703e-05,
      "loss": 4.8473,
      "step": 25500
    },
    {
      "epoch": 1.0,
      "eval_loss": 4.8997955322265625,
      "eval_runtime": 489.9016,
      "eval_samples_per_second": 45.266,
      "eval_steps_per_second": 2.829,
      "step": 25762
    }
  ],
  "logging_steps": 500,
  "max_steps": 77286,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0942279244471337e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
